{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS 156a, HW #8, P2-10\n",
    "Author: Liting Xiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in train/test data sets\n",
    "train_x = np.loadtxt('features.train', usecols=(1,2), unpack=True).T\n",
    "train_y = np.loadtxt('features.train', usecols=0)\n",
    "test_x = np.loadtxt('features.test', usecols=(1,2), unpack=True).T\n",
    "test_y = np.loadtxt('features.test', usecols=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P2-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0 vs all\":\n",
      "    E_in: 0.106; The number of support vectors: 2179\n",
      "\n",
      "\"1 vs all\":\n",
      "    E_in: 0.014; The number of support vectors: 386\n",
      "\n",
      "\"2 vs all\":\n",
      "    E_in: 0.100; The number of support vectors: 1970\n",
      "\n",
      "\"3 vs all\":\n",
      "    E_in: 0.090; The number of support vectors: 1950\n",
      "\n",
      "\"4 vs all\":\n",
      "    E_in: 0.089; The number of support vectors: 1856\n",
      "\n",
      "\"5 vs all\":\n",
      "    E_in: 0.076; The number of support vectors: 1585\n",
      "\n",
      "\"6 vs all\":\n",
      "    E_in: 0.091; The number of support vectors: 1893\n",
      "\n",
      "\"7 vs all\":\n",
      "    E_in: 0.088; The number of support vectors: 1704\n",
      "\n",
      "\"8 vs all\":\n",
      "    E_in: 0.074; The number of support vectors: 1776\n",
      "\n",
      "\"9 vs all\":\n",
      "    E_in: 0.088; The number of support vectors: 1978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def one_vs_all(train_x, train_y, digit,\n",
    "               kernel='poly', C=0.01, Q=2):\n",
    "    # create one_vs_all labels\n",
    "    digit_y = np.ones_like(train_y)\n",
    "    digit_y[train_y!=digit] = -1\n",
    "    \n",
    "    # SVM to get E_in\n",
    "    svc = SVC(C=C, kernel=kernel, degree=Q, gamma=1, coef0=1)\n",
    "    svc.fit(train_x, digit_y)\n",
    "    digit_pred = svc.predict(train_x)\n",
    "    N_svm = svc.support_vectors_.shape[0]\n",
    "    return N_svm, sum((digit_pred!=digit_y)) / float(len(digit_y))\n",
    "\n",
    "for d in range(0, 10):\n",
    "    N_svm, E_in = one_vs_all(train_x, train_y, d)\n",
    "    print('\"{} vs all\":'.format(d))\n",
    "    print('    E_in: {:.3f}; The number of support vectors: {}\\n'\n",
    "          .format(E_in, N_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The highest E_in is: [a] 0 vs all.\n",
    "3. The lowest E_in is: [a] 1 vs all.\n",
    "4. The number of SVs difference between \"0 vs all\" and \"1 vs all\" is thus: 2179-386=1793, closest to [c]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P5-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.0001, Q=2:\n",
      "    E_in: 0.009; E_out: 0.017\n",
      "    The number of support vectors is: 236\n",
      "\n",
      "C=0.0001, Q=5:\n",
      "    E_in: 0.004; E_out: 0.019\n",
      "    The number of support vectors is: 26\n",
      "\n",
      "C=0.001, Q=2:\n",
      "    E_in: 0.004; E_out: 0.017\n",
      "    The number of support vectors is: 76\n",
      "\n",
      "C=0.001, Q=5:\n",
      "    E_in: 0.004; E_out: 0.021\n",
      "    The number of support vectors is: 25\n",
      "\n",
      "C=0.01, Q=2:\n",
      "    E_in: 0.004; E_out: 0.019\n",
      "    The number of support vectors is: 34\n",
      "\n",
      "C=0.01, Q=5:\n",
      "    E_in: 0.004; E_out: 0.021\n",
      "    The number of support vectors is: 23\n",
      "\n",
      "C=0.1, Q=2:\n",
      "    E_in: 0.004; E_out: 0.019\n",
      "    The number of support vectors is: 24\n",
      "\n",
      "C=0.1, Q=5:\n",
      "    E_in: 0.003; E_out: 0.019\n",
      "    The number of support vectors is: 25\n",
      "\n",
      "C=1, Q=2:\n",
      "    E_in: 0.003; E_out: 0.019\n",
      "    The number of support vectors is: 24\n",
      "\n",
      "C=1, Q=5:\n",
      "    E_in: 0.003; E_out: 0.021\n",
      "    The number of support vectors is: 21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def data_for_1v1(x, y, digit1, digit2):\n",
    "    new_y = np.ones_like(y)\n",
    "    new_y[y==digit2] = -1\n",
    "    new_y = new_y[(y==digit1) | (y==digit2)]\n",
    "    new_x = x[(y==digit1) | (y==digit2)]\n",
    "    return new_x, new_y\n",
    "\n",
    "def one_vs_one(train_x, train_y, test_x, test_y, \n",
    "               digit1, digit2, kernel='poly', C=0.01, Q=2):\n",
    "    # get 'one_vs_one' ready data sets\n",
    "    x1, y1 = data_for_1v1(train_x, train_y, digit1, digit2)\n",
    "    x2, y2 = data_for_1v1(test_x, test_y, digit1, digit2)\n",
    "    \n",
    "    # SVM to get E_in\n",
    "    svc = SVC(C=C, kernel=kernel, degree=Q, gamma=1, coef0=1)\n",
    "    svc.fit(x1, y1)\n",
    "    N_svm = svc.support_vectors_.shape[0]\n",
    "    E_in = sum((svc.predict(x1)!=y1)) / float(len(y1))\n",
    "    E_out = sum((svc.predict(x2)!=y2)) / float(len(y2))\n",
    "    return N_svm, E_in, E_out\n",
    "\n",
    "for C in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "    N_svm, E_in, E_out = one_vs_one(\n",
    "        train_x, train_y, test_x, test_y, 1, 5, C=C, Q=2)\n",
    "    print('C={}, Q={}:'.format(C, 2))\n",
    "    print('    E_in: {:.3f}; E_out: {:.3f}'.format(E_in, E_out))\n",
    "    print('    The number of support vectors is: {}\\n'.format(N_svm))\n",
    "    \n",
    "    N_svm, E_in, E_out = one_vs_one(\n",
    "        train_x, train_y, test_x, test_y, 1, 5, C=C, Q=5)\n",
    "    print('C={}, Q={}:'.format(C, 5))\n",
    "    print('    E_in: {:.3f}; E_out: {:.3f}'.format(E_in, E_out))\n",
    "    print('    The number of support vectors is: {}\\n'.format(N_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [a] & [b]: The number of support vectors doesn't strictly go down.<br>\n",
    "   [c]: E_out doesn't always go down as C goes up.<br>\n",
    "   <b>[d]: This is true.</b>\n",
    "   <br><br>\n",
    "6. [a]: E_in is higher at Q=2. <br>\n",
    "   <b>[b]: This is True. </b> <br>\n",
    "   [c]: E_in's are the same here. <br>\n",
    "   [d]: E_out is larger at Q=5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P7-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Ecv(train_x, train_y, digit1, digit2, N_part,\n",
    "          kernel='poly', C=0.01, Q=2):\n",
    "    # partition into N_part folds to get val and train sets\n",
    "    part_x = np.array_split(train_x, N_part)\n",
    "    part_y = np.array_split(train_y, N_part)\n",
    "    E_cv = 0\n",
    "    for i in range(N_part):\n",
    "        val_x = part_x[i]\n",
    "        val_y = part_y[i]\n",
    "        train_x = np.concatenate(np.delete(part_x, i))\n",
    "        train_y = np.concatenate(np.delete(part_y, i))\n",
    "        \n",
    "        _, _, Err = one_vs_one(train_x, train_y, val_x, val_y,\n",
    "                               digit1, digit2, C=C)\n",
    "        E_cv += Err\n",
    "    return E_cv / float(N_part)\n",
    "\n",
    "complete_dict = {}\n",
    "for C in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "    complete_dict[C] = []\n",
    "\n",
    "C_list = []\n",
    "for epoch in range(100):\n",
    "    E_cv = {}    \n",
    "    for C in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
    "        E_cv[C] = get_Ecv(train_x, train_y, 1, 5, 10, C=C)\n",
    "        complete_dict[C].append(E_cv[C])\n",
    "    C_list.append(min(E_cv, key=E_cv.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. The most often selected is: 0.001\n",
      "8. The average E_cv for 0.001 is: 0.004436338940129589\n"
     ]
    }
   ],
   "source": [
    "values, cts = np.unique(C_list, return_counts=True)\n",
    "C_most = values[np.argmax(cts)]\n",
    "print('7. The most often selected is: {}'.format(C_most))\n",
    "Ecv_Cmost = np.mean(complete_dict[C_most])\n",
    "print('8. The average E_cv for {} is: {}'.format(C_most, Ecv_Cmost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P9-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01:\n",
      "    E_in: 0.004; E_out: 0.024\n",
      "\n",
      "C = 1:\n",
      "    E_in: 0.004; E_out: 0.021\n",
      "\n",
      "C = 100.0:\n",
      "    E_in: 0.003; E_out: 0.019\n",
      "\n",
      "C = 10000.0:\n",
      "    E_in: 0.003; E_out: 0.024\n",
      "\n",
      "C = 1000000.0:\n",
      "    E_in: 0.001; E_out: 0.024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for C in [1e-2, 1, 1e2, 1e4, 1e6]:\n",
    "    _, E_in, E_out = one_vs_one(train_x, train_y,\n",
    "        test_x, test_y, 1, 5, kernel='rbf', C=C)\n",
    "    print('C = {}:'.format(C))\n",
    "    print('    E_in: {:.3f}; E_out: {:.3f}\\n'.format(E_in, E_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. The lowest E_in happens when C=1e6.\n",
    "10. The lowest E_out happens when C=100."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
